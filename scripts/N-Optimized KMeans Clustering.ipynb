{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21xhU4zFI7HS"
   },
   "source": [
    "# K-Means Clustering (N-Optimized Version)\n",
    "\n",
    "This is a version of k-means algorithm in which it is precently applied an optimization technique. Basically this code performs a k-means to cluster faces. Each cluster is precedently sub-clustered in order to perform a better precision. The number of subclusters is choosen dynamically by the algorithm itself.\n",
    "\n",
    "##Optimization\n",
    "Before clustering, the dataset labelled to each subject is indipendently subclustered in n subclusters to increase the precision. This method is meant to reduce the number of elements per cluster in order to increase their spacial intercorrelation.\n",
    "\n",
    "##Optimum number of sub-clusters\n",
    "The optimum number of n is determined using elbow method within the elements of each clusters. This approach is characterized by a conservative approach, preferring an inferior number of sub-clusters in case of doubt situations \n",
    "\n",
    "##The code\n",
    "The code performs all the operations to prepare the clustering and the operations needed to pair the generated labels of the clustering with the old ones.\n",
    "\n",
    "##The testing\n",
    "Each subject has an old_label. That old_label is linked to other 2 labels. Each label is linked to one generated_label by the array solution.\n",
    "\n",
    "There are 2 ways to test the clustering. The first one starts from the subject to identify returning the corresponding labels. The second one starts from a testing file, returning the precision of the labelling operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ad-S66aIiFq"
   },
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unlDDnf4Hi-j"
   },
   "source": [
    "##Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNXuJrEiSDrR"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4305,
     "status": "ok",
     "timestamp": 1545067287219,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "qDmFHIF-TEod",
    "outputId": "88079ba4-d35f-4e52-da10-bbaa0e3ef013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size: 4320\n",
      "number_clusters: 62\n",
      "labels_h: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0]\n"
     ]
    }
   ],
   "source": [
    "#Dataset\n",
    "url = '../csv_files/final_training.csv' \n",
    "\n",
    "dataset = []\n",
    "\n",
    "#Read csv and put everything into a matrix\n",
    "reader = csv.reader(open(url), delimiter=\",\")\n",
    "x = list(reader)\n",
    "dataset = np.array(x).astype(\"float\")\n",
    "\n",
    "#Sort the dataset matrix to ensure consistent calculation\n",
    "row_length = dataset[0,:].size\n",
    "dataset = sorted(dataset,key=lambda x:x[row_length-1])\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "#Variables\n",
    "\n",
    "#Setting variables\n",
    "labels = dataset[:,(dataset.shape[1]-1)]\n",
    "dataset = dataset[:,:(dataset.shape[1]-1)]\n",
    "dataset_size = dataset[:,0].size\n",
    "row_length = dataset[0,:].size\n",
    "\n",
    "#Number of clusters\n",
    "number_clusters = 1\n",
    "for i in range(1, dataset_size):\n",
    "  if labels[i] != labels[i-1]:\n",
    "    number_clusters += 1\n",
    "    \n",
    "#Labels without repetitions\n",
    "labels_h = []\n",
    "labels_h.append(labels[0])\n",
    "for i in range(1, dataset_size):\n",
    "  if (labels[i] != labels[i-1]):\n",
    "    labels_h.append(labels[i])\n",
    "    \n",
    "old_labels = labels\n",
    "old_labels_h = labels_h\n",
    "    \n",
    "print('dataset_size:', dataset_size)\n",
    "print('number_clusters:', number_clusters)\n",
    "print('labels_h:', labels_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTs3Yb89xkq7"
   },
   "source": [
    "##Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6522,
     "status": "ok",
     "timestamp": 1545067297874,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "CO6kT-LCxkO7",
    "outputId": "822006de-5d53-4f1c-8a00-ee09c71d147a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimum number of subcluster: 3\n"
     ]
    }
   ],
   "source": [
    "#Max number of iterations\n",
    "#To avoid to go have too many clusters for time wasting\n",
    "max_subcluster = 5\n",
    "\n",
    "number_subclusters = 0\n",
    "isOptimum = 0\n",
    "# Used to determine the correct number of subclusters\n",
    "# It has to be minimized\n",
    "old_elbow_sum = 1000000\n",
    "\n",
    "while isOptimum == 0 and number_subclusters < max_subcluster:\n",
    "  number_subclusters += 1\n",
    "  \n",
    "  variances = []\n",
    "  #Subclustering and generation of new labels\n",
    "  for i in range(number_clusters):\n",
    "    curr_cluster = []\n",
    "\n",
    "    #Get the current label rows and their indexes\n",
    "    for j in range(dataset_size):\n",
    "      if old_labels[j] == old_labels_h[i]:\n",
    "        curr_cluster.append(dataset[j])\n",
    "      curr_cluster_size = len(curr_cluster)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=number_subclusters, random_state=0).fit(curr_cluster)\n",
    "    generated_labels = kmeans.labels_\n",
    "\n",
    "    #Validation of the subclusters\n",
    "    for l in range(number_subclusters):\n",
    "      curr_subcluster = []\n",
    "\n",
    "      #Get the subcluster\n",
    "      for q in range(curr_cluster_size):\n",
    "        if generated_labels[q] == l:\n",
    "          curr_subcluster.append(curr_cluster[q])\n",
    "      curr_subcluster_size = len(curr_subcluster)\n",
    "      \n",
    "      if curr_subcluster_size > 0:\n",
    "        #Get the centroid of all the points of the cluster\n",
    "        centroid = []\n",
    "        for q in range(row_length):\n",
    "          addend = 0\n",
    "          for s in range(curr_subcluster_size):\n",
    "            addend += curr_subcluster[s][q]\n",
    "          addend = addend / curr_subcluster_size\n",
    "          centroid.append(addend)\n",
    "\n",
    "        #Calculating the distances from the centroid\n",
    "        distances = []\n",
    "        for q in range(curr_subcluster_size):\n",
    "          addend = 0\n",
    "          for s in range(row_length):\n",
    "            addend += (curr_subcluster[q][s] - centroid[s]) * (curr_subcluster[q][s] - centroid[s])\n",
    "\n",
    "          distances.append(math.sqrt(addend))\n",
    "\n",
    "        distances_size = len(distances)\n",
    "\n",
    "        #Get the average mean\n",
    "        avg_mean = 0\n",
    "        for q in range(distances_size):\n",
    "          avg_mean += distances[q]\n",
    "        avg_mean = avg_mean/distances_size\n",
    "\n",
    "        #Get the variance\n",
    "        variance = 0\n",
    "        for q in range(distances_size):\n",
    "          variance += (distances[q] - avg_mean) * (distances[q] - avg_mean)\n",
    "        variance = variance / distances_size\n",
    "        variances.append(variance)\n",
    "      \n",
    "  #Check if the optimum criteria is met. Elbow method\n",
    "  elbow_sum = 0\n",
    "  for l in range(number_subclusters):\n",
    "    elbow_sum += variances[l]\n",
    "  \n",
    "  #Check if it is optimum\n",
    "  if old_elbow_sum <= elbow_sum :\n",
    "    isOptimum = 1\n",
    "    number_subclusters -= 1\n",
    "  else:\n",
    "    old_elbow_sum = elbow_sum\n",
    "\n",
    "print('optimum number of subcluster:', number_subclusters)\n",
    "\n",
    "#Subclustering in the proper number of subcluster\n",
    "for i in range(number_clusters):\n",
    "  curr_cluster = []\n",
    "  curr_cluster_index = []\n",
    "\n",
    "  #Get the current label rows and their indexes\n",
    "  for j in range(dataset_size):\n",
    "    if old_labels[j] == old_labels_h[i]:\n",
    "      curr_cluster.append(dataset[j])\n",
    "      curr_cluster_index.append(j)\n",
    "\n",
    "      #Pre updating labels\n",
    "      labels[j] = old_labels[j] * 1000\n",
    "\n",
    "  if len(curr_cluster) >= (number_subclusters):\n",
    "    #subclustering\n",
    "    kmeans = KMeans(n_clusters=number_subclusters, random_state=0).fit(curr_cluster)\n",
    "    generated_labels = kmeans.labels_\n",
    "\n",
    "    for j in range(generated_labels.size):\n",
    "      labels[curr_cluster_index[j]] = old_labels[curr_cluster_index[j]] + generated_labels[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99Q_Ddl1ONvm"
   },
   "outputs": [],
   "source": [
    "#Putting the optimized dataset back together\n",
    "dataset = np.insert(dataset, dataset.shape[1], labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qu0SOgl66vOV"
   },
   "outputs": [],
   "source": [
    "#Sort the dataset matrix for further elaboration\n",
    "dataset = sorted(dataset,key=lambda x:x[row_length])\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1545067314502,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "gy7m14560y4D",
    "outputId": "20854e17-5b6f-4fb6-a24e-bad7469b7d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size: 4320\n",
      "number_clusters: 186\n",
      "labels_h: [1000.0, 1001.0, 1002.0, 2000.0, 2001.0, 2002.0, 3000.0, 3001.0, 3002.0, 4000.0, 4001.0, 4002.0, 5000.0, 5001.0, 5002.0, 6000.0, 6001.0, 6002.0, 7000.0, 7001.0, 7002.0, 8000.0, 8001.0, 8002.0, 9000.0, 9001.0, 9002.0, 10000.0, 10001.0, 10002.0, 11000.0, 11001.0, 11002.0, 12000.0, 12001.0, 12002.0, 13000.0, 13001.0, 13002.0, 14000.0, 14001.0, 14002.0, 15000.0, 15001.0, 15002.0, 16000.0, 16001.0, 16002.0, 17000.0, 17001.0, 17002.0, 18000.0, 18001.0, 18002.0, 19000.0, 19001.0, 19002.0, 20000.0, 20001.0, 20002.0, 21000.0, 21001.0, 21002.0, 22000.0, 22001.0, 22002.0, 23000.0, 23001.0, 23002.0, 24000.0, 24001.0, 24002.0, 25000.0, 25001.0, 25002.0, 26000.0, 26001.0, 26002.0, 27000.0, 27001.0, 27002.0, 28000.0, 28001.0, 28002.0, 29000.0, 29001.0, 29002.0, 30000.0, 30001.0, 30002.0, 31000.0, 31001.0, 31002.0, 32000.0, 32001.0, 32002.0, 33000.0, 33001.0, 33002.0, 34000.0, 34001.0, 34002.0, 35000.0, 35001.0, 35002.0, 36000.0, 36001.0, 36002.0, 37000.0, 37001.0, 37002.0, 38000.0, 38001.0, 38002.0, 39000.0, 39001.0, 39002.0, 40000.0, 40001.0, 40002.0, 41000.0, 41001.0, 41002.0, 42000.0, 42001.0, 42002.0, 43000.0, 43001.0, 43002.0, 44000.0, 44001.0, 44002.0, 45000.0, 45001.0, 45002.0, 46000.0, 46001.0, 46002.0, 47000.0, 47001.0, 47002.0, 48000.0, 48001.0, 48002.0, 49000.0, 49001.0, 49002.0, 50000.0, 50001.0, 50002.0, 51000.0, 51001.0, 51002.0, 52000.0, 52001.0, 52002.0, 53000.0, 53001.0, 53002.0, 54000.0, 54001.0, 54002.0, 55000.0, 55001.0, 55002.0, 56000.0, 56001.0, 56002.0, 57000.0, 57001.0, 57002.0, 58000.0, 58001.0, 58002.0, 59000.0, 59001.0, 59002.0, 60000.0, 60001.0, 60002.0, 61000.0, 61001.0, 61002.0, 62000.0, 62001.0, 62002.0]\n"
     ]
    }
   ],
   "source": [
    "#Setting variables on optimized dataset\n",
    "labels = dataset[:,(dataset.shape[1]-1)]\n",
    "dataset = dataset[:,:(dataset.shape[1]-1)]\n",
    "dataset_size = dataset[:,0].size\n",
    "row_length = dataset[0,:].size\n",
    "\n",
    "#Number of clusters\n",
    "number_clusters = 1\n",
    "for i in range(1, dataset_size):\n",
    "  if labels[i] != labels[i-1]:\n",
    "    number_clusters += 1\n",
    "    \n",
    "#Labels without repetitions\n",
    "labels_h = []\n",
    "labels_h.append(labels[0])\n",
    "for i in range(1, dataset_size):\n",
    "  if (labels[i] != labels[i-1]):\n",
    "    labels_h.append(labels[i])\n",
    "    \n",
    "print('dataset_size:', dataset_size)\n",
    "print('number_clusters:', number_clusters)\n",
    "print('labels_h:', labels_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIbKEYP4QiSI"
   },
   "source": [
    "##Clustering Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNiXzIHsTmdV"
   },
   "outputs": [],
   "source": [
    "#Applying kmeans classifier\n",
    "kmeans = KMeans(n_clusters=number_clusters, random_state=0).fit(dataset)\n",
    "generated_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSIYKoMETKvf"
   },
   "outputs": [],
   "source": [
    "#Filling this array before doing the validation\n",
    "generated_labels_h = [] \n",
    "\n",
    "#Copy the list of the labels to avoid side effects\n",
    "sorted_generated_labels = generated_labels.copy()\n",
    "sorted_generated_labels.sort()\n",
    "\n",
    "#Extract generated labels without repetition\n",
    "generated_labels_h.append(sorted_generated_labels[0])\n",
    "for i in range(1, dataset_size):\n",
    "  if (sorted_generated_labels[i] != sorted_generated_labels[i-1]):\n",
    "    generated_labels_h.append(sorted_generated_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0n-gIZ7ISIu"
   },
   "source": [
    "##Matching Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p91yfqjzPSST"
   },
   "outputs": [],
   "source": [
    "#Building the flow matrix\n",
    "flow = []    \n",
    "\n",
    "for curr_label in range(number_clusters):\n",
    "  #Getting the precision flow per label index\n",
    "  precision_flow = np.zeros(number_clusters)\n",
    "  \n",
    "  #Getting the generated labels for the current labels\n",
    "  generated_curr_labels = []\n",
    "  for i in range(dataset_size):\n",
    "    if labels[i] == labels_h[curr_label]:\n",
    "      generated_curr_labels.append(kmeans.predict([dataset[i,:]]))\n",
    "\n",
    "  generated_curr_labels.sort()\n",
    "  curr_generated_label = generated_curr_labels[0]\n",
    "  curr_generated_label_occurrences = 1\n",
    "  \n",
    "  for i in range(1, len(generated_curr_labels)):\n",
    "    \n",
    "    if curr_generated_label != generated_curr_labels[i]:\n",
    "      #Se la label cambia si calcola la percentuale nel vettore indicizzato dalla label\n",
    "      precision_flow[curr_generated_label] = curr_generated_label_occurrences / len(generated_curr_labels) * 100\n",
    "      \n",
    "      curr_generated_label = generated_curr_labels[i]\n",
    "      curr_generated_label_occurrences = 1\n",
    "    else:\n",
    "      #If the label doesn't change, it is set one occurrence more\n",
    "      curr_generated_label_occurrences += 1\n",
    "  \n",
    "  #Otherwise the algorithm doesn't find the last item because there is no\n",
    "  #other element at the end to trigger the if condition\n",
    "  precision_flow[curr_generated_label] = curr_generated_label_occurrences / len(generated_curr_labels) * 100\n",
    "  \n",
    "  flow.append(precision_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPYqLfmpRQjy"
   },
   "outputs": [],
   "source": [
    "def calculate_matching(flow):\n",
    "  n = flow[0].size #number of subjects = number of clusters\n",
    "  problem = LpProblem(\"From Label to Cluster\", LpMinimize)\n",
    "  \n",
    "  #GENERATE LP PROBLEM VARIABLES\n",
    "  x = [[]]*n\n",
    "  for i in range(0, n):\n",
    "    x[i] = np.empty(n, dtype=LpVariable)\n",
    "    for j in range(0, n):\n",
    "      #generate variable which represents flux on edge (u, v) for all u representing labels and for all v representing clusters\n",
    "      exec(\"x[%d][%d] = LpVariable(\\\"x_%d_%d\\\",0,1,LpInteger)\" % (i, j, i, j))      \n",
    "  \n",
    "  #SET THE OBJECTIVE FUNCTION\n",
    "  problem += sum((-flow[i][j])*x[i][j] for i in range(0, n) for j in range(0, n)), \"Objective function\"\n",
    "  \n",
    "  #COSTRAINTS\n",
    "  problem += sum(x[i][j] for i in range(0, n) for j in range(0, n)) == n, \"Exactly n couples found\"\n",
    "  \n",
    "  #COSTRAINTS\n",
    "  for i in range(0, n):\n",
    "    str = \"Exactly one cluster for label %d\" %i\n",
    "    problem += sum(x[i][j] for j in range(0, n)) == 1, str\n",
    "    \n",
    "  #COSTRAINTS\n",
    "  for j in range(0, n):\n",
    "    str = \"Exactly one label for cluster %d\" %j\n",
    "    problem += sum(x[i][j] for i in range(0, n)) == 1, str\n",
    "    \n",
    "  #SOLVE\n",
    "  matching = [0]*n\n",
    "  #print(problem)\n",
    "  if problem.solve() == 1: #OPTIMUM OBTAINED: SET RETURN VALUES\n",
    "    for v in problem.variables():\n",
    "      if v.varValue == 1:\n",
    "        split = v.name.split(\"_\")\n",
    "        i = int(split[1])\n",
    "        j = int(split[2])\n",
    "        #uncomment to return an array where the i-th value is our custom label corresponding to the i-th cluster\n",
    "        #matching[j] = i\n",
    "        #uncomment to return an array where the i-th value is the cluster corresponding to the i-th subject\n",
    "        matching[i] = j\n",
    "        \n",
    "  else: \n",
    "    print(\"Matching not found!\")\n",
    "    \n",
    "  return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GN96MPhHMllv"
   },
   "outputs": [
    
   ],
   "source": [
    "#The array 'solution' links the index of the starting label\n",
    "#with the generated one. For example\n",
    "# let labels_h = [5, 7, 4, 2]\n",
    "# so solution[2] means the generatedd label corresponding to \n",
    "# the originary label 4\n",
    "solution = calculate_matching(flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeRyVa5VMo4q"
   },
   "source": [
    "##Validation Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 169544,
     "status": "ok",
     "timestamp": 1545067525130,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "hEtjh1MxBc1E",
    "outputId": "019cbd87-2539-4cfd-da4e-a83b7e43e20e"
   },
   "outputs": [],
   "source": [
    "#Set the overall precision of the model\n",
    "precision = []\n",
    "overall = 0\n",
    "for i in range(number_clusters):\n",
    "  precision.append(flow[i][solution[i]])\n",
    "  \n",
    "  #Number of items per cluster\n",
    "  number_items = 0\n",
    "  for j in range(dataset_size):\n",
    "    if labels_h[i] == labels[j]:\n",
    "      number_items += 1\n",
    "      \n",
    "  overall += (precision[i] * number_items)\n",
    "\n",
    "overall = overall / dataset_size\n",
    "print(overall, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6vtXcFjQdFe"
   },
   "source": [
    "##Plotting Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1900
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 170118,
     "status": "ok",
     "timestamp": 1545067528361,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "S0qKUmgxxOn-",
    "outputId": "bbc73628-af63-4227-e9b4-afe6b81e8b68"
   },
   "outputs": [],
   "source": [
    "#Normalizing data for visualization\n",
    "dataset_norm = (dataset - dataset.min())/(dataset.max() - dataset.min())\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "transformed = pd.DataFrame(pca.fit_transform(dataset_norm))\n",
    "\n",
    "plt.scatter(transformed[generated_labels==i][0], transformed[generated_labels==i][1], label=i)\n",
    "  \n",
    "  \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PuurrNbPdWo"
   },
   "source": [
    "##Testing Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 163944,
     "status": "ok",
     "timestamp": 1545067528362,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "1h-PQULqWGGz",
    "outputId": "4def886d-385a-4efc-e422-be4e790ce537"
   },
   "outputs": [],
   "source": [
    "subject = 10\n",
    "#Manual checking\n",
    "subject_label_index = [] # the indexes in labels_h of the subclustered labels\n",
    "subject_labels = [] # the subclustered label_h - for visualization only\n",
    "\n",
    "#Extraction of the originary labels belonging to the subject\n",
    "for i in range(number_clusters):\n",
    "  if old_labels_h[subject]*1000 <= labels_h[i]:\n",
    "    if (old_labels_h[subject]+1)*1000 > labels_h[i]:\n",
    "      subject_label_index.append(i)\n",
    "      subject_labels.append(labels_h[i]) #for visualization only\n",
    "\n",
    "error = 0\n",
    "num_items = 0\n",
    "subject_generated_labels = []  # for visualization only\n",
    "subject_correct_generated_labels = [] # for visualization only\n",
    "\n",
    "#Getting the precision\n",
    "for i in range(len(subject_label_index)):\n",
    "  curr_label = labels_h[subject_label_index[i]]\n",
    "  curr_solution = solution[subject_label_index[i]]\n",
    "  \n",
    "  for j in range(dataset_size):\n",
    "    if labels[j] == curr_label:\n",
    "      tested_label = kmeans.predict([dataset[j,:]])\n",
    "      subject_generated_labels.append(tested_label[0]) # for visualization only\n",
    "      subject_correct_generated_labels.append(curr_solution) # for visualization only\n",
    "      num_items += 1\n",
    "      \n",
    "      if tested_label != curr_solution:\n",
    "        error += 1\n",
    "\n",
    "#Printing\n",
    "print('Subject number:', subject)\n",
    "print('Dataset label:',old_labels_h[subject])\n",
    "print('Associated labels:',subject_labels)\n",
    "print()\n",
    "print('Solution labels:',subject_correct_generated_labels)\n",
    "print('Predicted labels:',subject_generated_labels)\n",
    "print('Precision:', (num_items-error)/num_items*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34061,
     "status": "ok",
     "timestamp": 1545067528598,
     "user": {
      "displayName": "Lucio Giordano",
      "photoUrl": "",
      "userId": "06146226138430505709"
     },
     "user_tz": -60
    },
    "id": "CQHyF2Bbn3oc",
    "outputId": "c7f34347-59cc-47c5-a558-0ec3212a59b1"
   },
   "outputs": [],
   "source": [
    "#Test from dataset\n",
    "url = \"../csv_files/testing/1_Indoor_lights_cooperative_testing.csv\"\n",
    "\n",
    "test_dataset = []\n",
    "\n",
    "#Read csv and put everything into a matrix\n",
    "reader = csv.reader(open(url), delimiter=\",\")\n",
    "x = list(reader)\n",
    "test_dataset = np.array(x).astype(\"float\")\n",
    "\n",
    "#Variables of the testing dataset\n",
    "test_labels = test_dataset[:,(test_dataset.shape[1]-1)]\n",
    "test_dataset = test_dataset[:,:(test_dataset.shape[1]-1)]\n",
    "test_dataset_size = test_dataset[:,0].size\n",
    "\n",
    "#Predict\n",
    "tested_predicted_labels = kmeans.predict(test_dataset)\n",
    "\n",
    "correct_matchings = 0\n",
    "wrong_matchings = 0\n",
    "\n",
    "for i in range(test_dataset_size):\n",
    "  \n",
    "  for j in range(number_clusters):\n",
    "    if solution[j] == tested_predicted_labels[i]:\n",
    "      paired_sublabel = labels_h[j]\n",
    "      originary_label = int(round(labels_h[j]/1000))\n",
    "      \n",
    "      if (test_labels[i] == originary_label):\n",
    "        correct_matchings += 1\n",
    "      else:\n",
    "        wrong_matchings += 1\n",
    "        \n",
    "print('Correct Matchings:', correct_matchings)\n",
    "print('Wrong Matchings:', wrong_matchings)\n",
    "print('Precision: ', correct_matchings / (correct_matchings + wrong_matchings) * 100, '%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "N-Optimized KMeans Clustering.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
